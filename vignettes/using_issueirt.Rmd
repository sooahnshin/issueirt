---
title: "Using `issueirt`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{using_issueirt}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(rmarkdown.html_vignette.check_title = FALSE)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  fig.width = 10,
  fig.height = 10
)
```

## Overview

This vignette provides a brief introduction to the `issueirt` package. The package is designed to fit `IssueIRT` model, a hierarchical Item Response Theory (IRT) model proposed by [@issueirt]. Specifically, `IssueIRT` estimates an issue-specific axis in a latent policy space, which represents a continuum extending from left to right positions on the issue, using roll-call votes and their issue labels. This approach first estimates multidimensional ideal points using all available voting data, which are then projected onto issue-specific axes to generate single-dimensional, issue-specific ideal points.

In this vignette, we will be using a synthetic dataset to demonstrate how to fit the `IssueIRT` model using the `issueirt` package. The dataset is generated using the `generate_data` function, which is also included in the package. The `IssueIRT` model is then fit to the dataset using the `issueirt_stan` function, after a few preprocessing steps.

### Installation

You can install `issueirt` package from GitHub using the `devtools` package:

```{r setup, eval=FALSE}
# install.packages("devtools")
devtools::install_github("sooahnshin/issueirt@dev", build_vignettes = TRUE))
```

## Step 1: Prepare the data

### Generate synthetic data

First, we generate a synthetic dataset using the `generate_data` function. 

```{r generate_data}
library(issueirt)
synth_data <- generate_data(seed = 02138,
                            n = 100,
                            m = 150, 
                            k = 6,
                            kappa = 12,
                            rho = 15,
                            a = 0.01, 
                            b = 0.001,
                            theta = 0:5 * pi/6)
```

Here are the details about the arguments:

| Argument | Description |
|----------|-------------|
| `seed`   | Random seed for reproducibility |
| `n`      | Number of legislators |
| `m`      | Number of bills |
| `k`      | Number of issue labels |
| `kappa`  | Standard deviation of $w_j$ (determines the deviation of the distance between Yea and Nay positions) |
| `rho`    | Concentration parameter of $u_j$ (determines the deviation of the roll call votes from its issue axis) |
| `a`      | Hyperparameter for the prior of the issue vector ($\theta_z$) and its concentration parameter ($\rho$) |
| `b`      | Hyperparameter for the prior of the issue vector ($\theta_z$) and its concentration parameter ($\rho$); $0<b<a$ |
| `theta`  | True issue vectors, $\theta_z$ |

We visualize the synthetic data for an illustration of how it looks like.


```{r visualize_true_helper}
## helper function to visualize the synthetic data
library(dplyr)
library(stringr)
library(ggplot2)
library(tidyr)
library(tibble)
library(purrr)
theme_set(theme_classic(base_size = 15) + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)))

#' function to create group assignment
#' in case of real data, you may use the party id, etc.
#' @param synth_data a list object generated by generate_data
#' @param legis_id a character vector of legislator id
#' @return a tibble
create_group <- function(synth_data, legis_id) {
  df <- synth_data$data$X |> 
    as_tibble() |>
    mutate(id = legis_id) |>
    mutate(
      # Determine the threshold for top 30% of V2
      top_30_percent_V2 = quantile(V2, 0.7, type = 7),  # Adjust 'type' as necessary
      group = case_when(
        V2 > top_30_percent_V2 ~ "C",  # Assign Group C for top 30% of V2
        TRUE ~ NA_character_  # Temporarily fill others with NA
      )
    ) |>
    # Now, assign Groups A and B for the remaining using V1
    mutate(
      group = if_else(is.na(group),  # Only assign A or B if not already in C
                      case_when(
                        V1 <= median(V1[is.na(group)]) ~ "A",  # Bottom 50% of remaining in V1
                        TRUE ~ "B"  # Top 50% of remaining in V1
                      ),
                      group  # Keep existing group assignment for C
      )
    ) |>
    select(-top_30_percent_V2)
  return(df)
}
```

```{r visualize_true}
## assign legis/bill id
legis_id <- paste0("legis", 1:dim(synth_data$data$Y)[1])
bill_id <- paste0("bill", 1:dim(synth_data$data$Y)[2])
true_legis <- create_group(synth_data, legis_id)

## visualize the synthetic data
plot_ideal(ideal_point_1d = true_legis$V1, true_legis$V2,
           group = true_legis$group, p.title = "True Ideal Points",
           breaks.group = c("A", "B", "C"), values.shape = c(17,18,19), values.color = c("indianred", "steelblue", "darkgreen"))
```

### (Optional) Filter votes and legislators

Before fitting the model, we may want to filter out votes and legislators with marginal amount of information.

Specifically, researcher may want to avoid using (1) lop-sided votes, or (2) legislators with marginal amount of votes.
(1) might not be a problem for the model fit, and we recommend just excluding unanimous votes.
(2) may result in high uncertainty in those legislators' ideal points.

To begin with, we create a `rollcall` object using the `pscl` package so that we can filter votes and legislators if needed.

```{r create_rollcall}
## data.frame containing id and group information
raw_legis <- true_legis |>
  select(id, group)
raw_bills <- tibble(id = bill_id)
rc <- pscl::rollcall(synth_data$data$Y,
                     yea = 1, nay = 0, missing = NA,
                     legis.names = raw_legis$id, legis.data = raw_legis,
                     vote.names = raw_bills$id, vote.data = raw_bills)
```

Now we filter out votes and legislators before fitting the model as below.
We recommend to use `filter_votes()` function to track the removed votes and legislators.

```{r filter_votes}
## drop (1) unanimous votes and (2) legislators with marginal amount of votes (< 20)
## update data.frame with filtered votes and legislators
filtered <- filter_votes(rc, lop = 0, minvotes = 20)
bills <- raw_bills[filtered$bills,]
legis <- raw_legis[filtered$legis,] 
votes <- rc$votes[filtered$legis, filtered$bills]
```

## Step 2: Fix the sign-flip

For the identification of the model, we need to fix the sign-flip (please refer to the paper for more details).
Note that this step is necessary for a real dataset, but not for synthetic data generated with `generate_data`.

We can use the `recode_votes` function to recode votes in the following coding rule: 
- `1` indicates a liberal majority (or conservative minority), and 
- `0` indicates a conservative majority (or liberal minority).

```{r recode_votes}
recoded_votes <- recode_votes(votes, 
                              party_code = legis$group, 
                              liberal_code = "A", # group A is liberal group
                              conservative_code = "B", # group B is conservative group
                              na_threshold = 0.5) # if the proportion of missing values is greater than 0.5, the vote is not recoded
```

We use `rollcall` object from the `pscl` package as the main input.

```{r create_rollcall_recoded}
rc_input <- pscl::rollcall(recoded_votes,
                           yea = 1, nay = 0, missing = NA,
                           legis.names = legis$id, legis.data = legis,
                           vote.names = bills$id, vote.data = bills)
```

In case of synthetic data generated with `generate_data`, we may skip this step since the data already follows the coding rule.

```{r create_rollcall_recoded_synthetic}
rc_input <- pscl::rollcall(votes, # original votes that are not recoded
                           yea = 1, nay = 0, missing = NA,
                           legis.names = legis$id, legis.data = legis,
                           vote.names = bills$id, vote.data = bills)
```

## Step 3: Starting values

We use Bayesian IRT model to generate the starting values for the `IssueIRT` model.
First, we can use `ideal()` function from the `pscl` package to fit the model.
You may want to increase the number of iterations, thinning, and burn-in based on the convergence diagnostics.

```{r starting_values}
## fit the Bayesian IRT model
set.seed(1)
ideal <- pscl::ideal(rc_input, dropList = list(lop = 0, legisMin = 0), # no need to further drop votes and legislators
                     priors = NULL, startvals = "eigen", # default priors and starting values
                     d = 2, maxiter = 5000, thin = 1, burnin = 4800,
                     impute = FALSE, normalize = FALSE,
                     store.item = TRUE, file = NULL, verbose = FALSE)
```
Recall that Bayesian IRT model has identification problem, and thus we fix $d+1$ number of legislators' ideal points.
We can use `find_pol_rc_horizontal()`, `find_pol_rc_vertical()`, and `find_constraints()` function to select those anchors as follows.

- `find_pol_rc_horizontal()`: Find the most polarized roll call in terms of horizontal division.
- `find_pol_rc_vertical()`: Find the most polarized roll call in terms of vertical division.
- `find_constraints()`: Find the anchors based on the most polarized roll calls.

Alternatively, you may use manually selected legislators using domain knowledge, or pick the legislators based on the visualization of the fitted Bayesian IRT model.

Also, we can use these anchors later to post-process the `IssueIRT` model to visualize the estimated multidimensional ideal points.
Note that the issue-specific ideal points are robust to rotational invariance (please refer to the paper for more details).

```{r find_anchors}
pol_rc1 <- find_pol_rc_horizontal(rc_input, party_code_col = "group", liberal_code = "A", conservative_code = "B", na_threshold = 0.3)
pol_rc2 <- find_pol_rc_vertical(ideal, rc_input, pol_rc1, party_code_col = "group", na_threshold = 0.3, lop_threshold = 0.1)

const_ls <- find_constraints(ideal, rc_input, pol_rc1 = pol_rc1, pol_rc2 = pol_rc2, party_code_col = "group", left_party_code = "A", top_party_code = "C", as_list = TRUE)
print(const_ls)
```

Based on these anchors, we post-process the Bayesian IRT model to generate the starting values for the `IssueIRT` model.
We use `postProcess()` function from the `pscl` package.

```{r post_process_birt}
## suppress redundant messages
invisible(capture.output({
  ideal_pp <- pscl::postProcess(ideal, constraints = const_ls)
}))
```

The starting values of ideal points can be visualized as follows. 
Based on this visualization, you may want to adjust the anchors if needed.

```{r visualize_starting_values}
plot_ideal(ideal_point_1d = ideal_pp$xbar[,1], ideal_point_2d = ideal_pp$xbar[,2],
           group = legis$group, p.title = "BIRT Estimates of Ideal Points",
           breaks.group = c("A", "B", "C"), values.shape = c(17,18,19), values.color = c("indianred", "steelblue", "darkgreen"))
```

## Step 4: Make inputs for the model

Now, we are ready to make inputs for the `issueirt_stan` function.
We can use `make_stan_input()` function to create the inputs.

```{r make_stan_input}
stan_input <- make_stan_input(
  issue_code_vec = synth_data$stan$z, # user-supplied issue labels
  rollcall = rc_input, # rollcall object
  ideal = ideal_pp, # starting values
  a = 0.01, b = 0.001, rho_init = 10 # hyperparameters
)
```

## Step 5: Fit the model

Finally, we fit the `IssueIRT` model using the `issueirt_stan` function.
You may want to adjust the number of chains, warmup, and iterations based on the convergence diagnostics and the computational resources.

```{r fit_model}
fit_sim <- issueirt_stan(
  data = stan_input$data,   
  init = list(stan_input$init, stan_input$init), # starting values
  chains = 2,             # number of Markov chains
  warmup = 10,           # number of warmup iterations per chain
  iter = 20,             # total number of iterations per chain
  cores = 2,              # number of cores (could use one per chain)
  seed = 1
)
```

## Step 6: Post-process the model parameters

After fitting the model, we can post-process the model to visualize the estimated issue-specific ideal points.
As aforementioned, the issue-specific ideal points are invariant to rotational transformations.
However, the multidimensional ideal points are not invariant to rotational transformations as it is in other IRT models, and thus we need to fix this identification problem by using the anchors, for example.

We can post-process the model using the user-supplied anchors and compute the posterior summaries of the estimated parameters as follows.

```{r post_process}
# missing_label <- make_missing_indicator(rc_input) # missing indicator (optional)
posterior_summary_pp <- make_posterior_summary_postprocessed(
  stan_fit = fit_sim, constraints = const_ls, issue_label = paste0("Issue ", 1:6),
  rc_label = bills$id, legis_label = legis$id, missing_label = NULL
)
```

The main quantities are as follows:
- `posterior_summary_pp$x_postprocessed`: A tibble of the estimated ideal points.
- `posterior_summary_pp$theta_postprocessed`: A tibble of the estimated issue vectors (mean direction, $\theta_z$).
- `posterior_summary_pp$u_postprocessed`: A tibble of the estimated roll call vectors ($u_j$).
Each tibble contains the posterior mean, standard deviation, and quantiles of the estimated parameters.

### Visualization

Now, we visualize the estimated parameters using its posterior mean.

```{r visualize_posterior}
plot_ideal(ideal_point_1d = posterior_summary_pp$x_postprocessed |> filter(dimension == 1) |> pull(mean), 
           ideal_point_2d = posterior_summary_pp$x_postprocessed |> filter(dimension == 2) |> pull(mean),
           group = legis$group, p.title = "IssueIRT Estimates of Ideal Points (Postprocessed)",
           breaks.group = c("A", "B", "C"), values.shape = c(17,18,19), values.color = c("indianred", "steelblue", "darkgreen"))
```

We can also visualize issue specific axes using `plot_issueirt()` function.

```{r visualize_issueirt}
p_ls <- plot_issueaxis(stan_input = stan_input, 
              posterior_summary = posterior_summary_pp,
              group = legis$group, p.title = "IssueIRT",
              breaks.group = c("A", "B", "C"), values.shape = c(17,18,19), values.color = c("grey", "grey", "grey"))

library(patchwork)
wrap_plots(p_ls) +
  plot_layout(ncol = 3, guides = "collect")
```

Here, each figure visualizes issue specific axis with the following elements:
- Points: multidimensional ideal points
- Black line: issue specific axis
- Grey lines: roll call axes in such issue area ($j$ such that $z_j = z$)
- Dark orange arrow: direction of issue specific axis ($\theta_z$)
- Light orange arrows: direction of roll call axes ($u_j$)

One important thing to note is that, using these plots, one can correct any coding error for sign-flip in the previous step. 
For example, if a direction of roll call axis is opposite to the direction of issue specific axis, it indicates that the sign of the roll call axis is flipped. 
In this case, researcher can correct the sign of the roll call axis by flipping $0/1$ to $1/0$ for such roll call and then fit the model again.

Lastly, since this is a synthetic data where the true parameters are known, we can compare the estimated parameters with the true parameters.

```{r visualize_posterior_helper}
## helper function to visualize the synthetic data
#' function to plot the synthetic data
#' @param true a numeric vector of true values
#' @param est a numeric vector of estimated values
#' @param p.xlab a character of x-axis label
#' @param p.ylab a character of y-axis label
#' @param p.title a character of plot title
#' @return a ggplot object
plot_synth <- function(true, est, p.xlab = NULL, p.ylab = NULL, p.title = NULL) {
  res <- data.frame(true, est)
  plot <- ggplot(res, aes(x = true, y = est)) +
    geom_point(alpha = 0.8) +
    theme_classic() +
    geom_abline(slope = 1, intercept = 0, lty = "dashed", color = "red") +
    labs(x = p.xlab, y = p.ylab, title = p.title)
  return(plot)
}
```

```{r visualize_posterior_simulation}
plot_synth(true = true_legis$V1, 
           est = posterior_summary_pp$x_postprocessed |> filter(dimension == 1) |> pull(mean), 
           p.title = "Dimension 1", p.xlab = "True", p.ylab = "Estimate (IssueIRT)")
plot_synth(true = true_legis$V2, 
           est = posterior_summary_pp$x_postprocessed |> filter(dimension == 2) |> pull(mean), 
           p.title = "Dimension 2", p.xlab = "True", p.ylab = "Estimate (IssueIRT)")
plot_synth(true = 0:5 * pi/6, 
           est = posterior_summary_pp$theta_postprocessed |> pull(mean), 
           p.title = expression("Mean Direction Vector ("*theta*")"), p.xlab = "True", p.ylab = "Estimate (IssueIRT)")
```

## Step 7: Compute posterior statistics

We can compute the posterior statistics to assess the convergence of the model.
As a warm-up, we start by computing the computation time.

```{r computation}
library(rstan)
elapsed_times <- get_elapsed_time(fit_sim)
## convert into minutes
elapsed_times_min <- elapsed_times / 60
## create a data frame for the table
summary_elapsed_times <- data.frame(
  Chain = 1:nrow(elapsed_times_min),
  Warmup = round(elapsed_times_min[, "warmup"], 2),
  Sampling = round(elapsed_times_min[, "sample"], 2)
)
## print table
summary_elapsed_times |> knitr::kable()
```

We can compute $\hat{R}$ statistics and effective sample size (ESS) using functions from `posterior` package, for example.

```{r posterior_statstics_helper}
## helper function to summarize draws
#' function to summarize the convergence statistics
#' @param draws_summary a data frame of draws summary
#' @return a tibble
calculate_convergence_summary <- function(draws_summary) {
  tibble(
    `Min of $\\hat{R}$` = quantile(draws_summary$rhat, 0),
    `25\\% of $\\hat{R}$` = quantile(draws_summary$rhat, 0.25),
    `Median of $\\hat{R}$` = quantile(draws_summary$rhat, 0.5),
    `75\\% of $\\hat{R}$` = quantile(draws_summary$rhat, 0.75),
    `Max of $\\hat{R}$` = quantile(draws_summary$rhat, 1),
    `Mean of $\\hat{R}$` = mean(draws_summary$rhat),
    `Min of ESS` = quantile(draws_summary$ess_bulk, 0),
    `25\\% of ESS` = quantile(draws_summary$ess_bulk, 0.25),
    `Median of ESS` = quantile(draws_summary$ess_bulk, 0.5),
    `75\\% of ESS` = quantile(draws_summary$ess_bulk, 0.75),
    `Max of ESS` = quantile(draws_summary$ess_bulk, 1),
    `Mean of ESS` = mean(draws_summary$ess_bulk)
  )
}
```


```{r posterior_statstics}
## get posterior samples (not just summary as in the previous step)
posterior_samples <- post_process(stan_fit = fit_sim, constraints = const_ls, legis_label = legis$id, as_mcmc = TRUE)
posterior_samples_list <- list(
  x1 = posterior_samples$x1,
  x2 = posterior_samples$x2,
  theta = posterior_samples$theta,
  u = posterior_samples$u
)

## convert to draws array format and summarize
summarized_draws <- posterior_samples_list %>%
  map(~ posterior::summarise_draws(posterior::as_draws_array(.)))

## quantiles of statistics for each type of parameters
quantiles <- summarized_draws|>
  map_df(calculate_convergence_summary, .id = "Parameter") |>
  mutate(Parameter = case_when(
    Parameter == "x1" ~ "$x_{i1}$",
    Parameter == "x2" ~ "$x_{i2}$",
    Parameter == "theta" ~ "$\\theta_{z}$",
    Parameter == "u" ~ "$u_{j}$"
  ))

## print results in table
quantiles |> select(Parameter, contains("\\hat{R}")) |> knitr::kable(digits = 2)
quantiles |> select(Parameter, contains("ESS")) |> knitr::kable()
```

If needed, we may want to adjust the number of chains, warmup, and iterations based on these convergence diagnostics.

## Step 8: Calculate issue-specific ideal points

Finally, using the fitted parameters from the `IssueIRT` model, we can calculate the issue-specific ideal points with the `get_ideal_points()` function.
We can use `plot_issueirt()` function to visualize the issue-specific ideal points.

```{r calculate_issue_specific}
issue_irt <- get_ideal_points(stan_fit = fit_sim, issue_label = paste0("Issue ", 1:6), legis_label = legis$id, legis_group = legis$group)
plot_issueirt(issueirt = issue_irt, p.title = "Issue Specific Ideal Points",
              breaks.group = c("A", "B", "C"), values.shape = c(17,18,19), values.color = c("indianred", "steelblue", "darkgreen"))
```

